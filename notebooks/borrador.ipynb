{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NOTAS IPre\n",
    "\n",
    "- Mis Tareas:\n",
    "    - Terminar primera modificación mínima\n",
    "    - Investigar el funcionamiento de la libreria Networkx\n",
    "    - Preparar visualizacion de grafo\n",
    "    - Estudiar en que consiste las visualizaciones\n",
    "    - Link de visualizaciones: \n",
    "        - https://brian.discourse.group/t/network-dynamics-visualizer/828/14 \n",
    "        - https://julianstier.com/posts/2024/10/animated-graph-models-with-python-interactive/ \n",
    "    - Elaboración de ordenamiento\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Resumen modificaciones: \n",
    "    - 1) Cambio esencial: **Se modifica el ordenamiento de los nodos**, si bien se mantienen 9 inputs arbitrarios cuyos pares de conexión interna se inicializan de forma no estructurada. Es decir, cambiamos solo la referencia espacial , pero seguimos teniendo 8 vecinos fijos conectados al central \n",
    "\n",
    "    - 2) Se define la estructura exacta del adjacency_map  con Networkx\n",
    "\n",
    "    - 3) Se decide elegir una topologia básica para comenzar con la modificación, k=8 , donde cada grafo tiene dos vecinos\n",
    "\n",
    "    - 4) \n",
    "\n",
    "    - 3) El modelo original percibe espacialmente los vecinos de manera fija, por lo que está diseñado para deducir su posición. La actual modificación elimina este ordenamiento espacial, por lo tanto la pregunta es ¿el nuevo ordenamiento debe ser explicito o se reemplaza por una nueva función que determina ese ordenamiento?\n",
    "        - ¿Cómo se asignan las conexiones lógicas hacia el nodo?: \n",
    "           - Respuesta del profesor Mircea es que debo definir una convención\n",
    "\n",
    "\t- 3) ¿Como funcionará la percepción sin parches espaciales?, ¿los parches serán globales, es decir sobre toda la imagen? ¿los parches de percepción se solaparán?\n",
    "\n",
    "- Definir exactamente que se modificó del codigo fuente: \n",
    "    - Contenido primera modificacion:\n",
    "    - Get Moore conection\n",
    "\t- Modificar Hyperparams\n",
    "\t- eliminar get grid patches\n",
    "\t- crear def get_adjacency_patches\n",
    "\t- modificar patches de def run async\n",
    "\t- modificar patches de def run sync\n",
    "\t- Modificar return y reaarrange de def run_perceive\n",
    "\t- Modificar argumentos de init_gate_layer de def init_logic_gate_netwo\n",
    "\t- Modificar  elif connections == 'first_kernel’. de init gate layer\n",
    "\n",
    "- Elaborar hipótesis de que va a suceder con la modificación: \n",
    "\n",
    "- Ejecucion de la primera modificación \n",
    "\t- Reemplazar funciones clave\n",
    "\t- Arreglar desajustes de Forma (error en las listas)\n",
    "    - Integrar visualización de la dinámica del grafo (Matplotlib)\n",
    "\t- Ejecutar los cambios\n",
    "\n",
    "- Conversaciones con Chatbots:\n",
    "    - Acerca de una mínima modificación: https://gemini.google.com/app/3cd3af930d62227d\n",
    "    - Construir lista de adyacencia a partir de nueva función de `get_graph_neighborhoods` https://gemini.google.com/app/79630204a7d79db3 \n",
    "    - Diferencia entre parte del modelo teórico y parte experimental  y visualización de un grafo https://g.co/gemini/share/e4cb72700fc3 \n",
    "    - Documentacion de modificaciones: https://gemini.google.com/app/3cd3af930d62227d?pli=1  \n",
    "\n",
    "- Bibliografía:   \n",
    "    - https://github.com/Felix-Petersen/difflogic/tree/main \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Propuesta (IA) de Estructura para Informe de Modificación de Código\n",
    "https://gemini.google.com/share/cc37f21c9c19\n",
    "\n",
    "1. Contexto y Objetivos\n",
    "Aquí estableces el panorama completo. Combinas tus puntos de \"Objetivo General\", \"Específico\" y el \"Porqué\".\n",
    "\n",
    "Objetivo General: Describe el propósito de alto nivel.\n",
    "\n",
    "Ejemplo: \"Optimizar el rendimiento computacional del pipeline de percepción en DiffLogicCA\" o \"Extender la funcionalidad de DiffLogicCA para soportar vecindarios no homogéneos\".\n",
    "\n",
    "Problema (La Motivación o el \"Porqué\"): Describe el problema específico que detectaste.\n",
    "\n",
    "Ejemplo: \"La implementación actual de get_grid_patches utiliza operaciones [X] que resultan ser un cuello de botella en GPUs [Y] cuando el grid supera la dimensión [Z], o no permite la extracción de patches irregulares...\".\n",
    "\n",
    "Objetivo Específico (La Solución Propuesta): Enuncia tu hipótesis o la meta concreta.\n",
    "\n",
    "Ejemplo: \"Modificar la función get_grid_patches para reemplazar [método antiguo] por [método nuevo, ej: una operación basada en convoluciones o tf.gather_nd] con el fin de reducir el tiempo de cómputo en un [X]%\".\n",
    "\n",
    "2. Análisis de la Implementación Original\n",
    "Este paso es crucial y faltaba en tu borrador. Antes de mostrar tu cambio, debes demostrar que entiendes el código existente.\n",
    "\n",
    "Función: get_grid_patches\n",
    "\n",
    "Comportamiento Actual: Explica qué hace la función, cuáles son sus entradas (inputs) y salidas (outputs).\n",
    "\n",
    "Fragmento de Código Relevante (Original): Pega el bloque de código original que vas a modificar.\n",
    "\n",
    "Análisis del Problema: Explica por qué ese bloque de código específico causa el problema que mencionaste en la motivación (ej. ineficiencia de memoria, complejidad algorítmica, etc.).\n",
    "\n",
    "3. Descripción de la Modificación (El \"Qué\" y el \"Cómo\")\n",
    "Este es el núcleo de tu informe (tu punto \"Modificación que propongo\" y \"Documento proceso de modificación\").\n",
    "\n",
    "Diseño de la Solución: Explica la lógica de tu nuevo enfoque.\n",
    "\n",
    "Ejemplo: \"La nueva implementación utilizará tf.nn.conv2d configurando un kernel de identidad para actuar como una ventana deslizante...\" o \"Se usará tf.einsum para...\".\n",
    "\n",
    "Implementación (Código Modificado): Muestra el código nuevo. Si es mucho, muestra un \"diff\" (diferencias) o solo la nueva función.\n",
    "\n",
    "Impacto en Dependencias: ¿Tu cambio afecta a otras funciones que llamaban a get_grid_patches? ¿Cambiaste la firma de la función (sus argumentos o lo que retorna)?\n",
    "\n",
    "4. Metodología de Validación y Pruebas\n",
    "¿Cómo sabes que tu cambio funciona correctamente y que realmente soluciona el problema?\n",
    "\n",
    "Ambiente de Pruebas: Hardware (CPU, GPU, TPU), versiones de software (TensorFlow, JAX, Python).\n",
    "\n",
    "Pruebas de Correctitud (Unit Tests): ¿Cómo verificaste que la nueva función produce exactamente el mismo resultado (o el resultado esperado) que la antigua?\n",
    "\n",
    "Ejemplo: \"Se creó un script que compara la salida de ambas funciones con datos de entrada aleatorios, asegurando que la diferencia absoluta sea menor a [1e-6]\".\n",
    "\n",
    "Pruebas de Rendimiento (Benchmarking): ¿Cómo mediste el impacto?\n",
    "\n",
    "Ejemplo: \"Se midió el tiempo de ejecución de la función [N] veces sobre grids de tamaños [S, M, L]...\".\n",
    "\n",
    "5. Resultados y Análisis\n",
    "Aquí presentas la evidencia (tu punto \"Resultados\" e \"Interpretación\").\n",
    "\n",
    "Resultados de Correctitud: (Ej. \"Las pruebas unitarias pasaron exitosamente\").\n",
    "\n",
    "Resultados de Rendimiento: Muestra los datos crudos. Una tabla o un gráfico comparando \"Antes\" vs. \"Después\" (ej. tiempo en ms, uso de memoria en GB) es ideal. *\n",
    "\n",
    "Interpretación y Discusión: Traduce los números a conclusiones.\n",
    "\n",
    "Ejemplo: \"Como muestra el Gráfico 1, la nueva implementación de get_grid_patches logró una aceleración promedio de 2.5x... Esto se debe a que la operación [nueva] está mejor optimizada por [XLA/CUDA] que la operación [antigua]...\".\n",
    "\n",
    "6. Conclusión y Trabajo Futuro\n",
    "Cierra el informe.\n",
    "\n",
    "Resumen de Logros: (Ej. \"Se modificó exitosamente la función... cumpliendo el objetivo de optimización...\").\n",
    "\n",
    "Pasos Siguientes: ¿Qué sigue ahora?\n",
    "\n",
    "Ejemplo: \"Hacer un Pull Request al repositorio\", \"Explorar si esta misma técnica se puede aplicar a la función [otra_funcion]...\", \"Este cambio desbloquea la posibilidad de...\". \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Nueva, pero eliminada,tiene errores \n",
    "#nueva Test de Verificación de Dimensiones \n",
    "# Ubicación: Celda 15\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "key_init, key = jax.random.split(key, 2)\n",
    "n_kernels = 4\n",
    "layers = [128] * 10 + [64, 32, 16]\n",
    "connections = ['unique'] * len(layers)\n",
    "\n",
    "\n",
    "hyperparams = {\n",
    "    'update': {'layers': layers, 'connections': connections},\n",
    "    'perceive': {\n",
    "        'n_kernels': n_kernels,\n",
    "        'layers': [9, 8, 4, 2, 1],\n",
    "        # CORRECCIÓN 1: Usar 'unique' en lugar de 'first_kernel'\n",
    "        'connections': ['unique', 'unique', 'unique', 'unique'], \n",
    "    },\n",
    "}\n",
    "\n",
    "training = True\n",
    "params, wires = init_diff_logic_ca(hyperparams, key_init)\n",
    "print(\n",
    "    params['perceive'][0]\n",
    "    .reshape((\n",
    "        hyperparams['perceive']['n_kernels'],\n",
    "        hyperparams['perceive']['layers'][1],\n",
    "        16,\n",
    "    ))\n",
    "    .shape\n",
    ")\n",
    "grid_ch_dim = 16\n",
    "inp = jnp.ones((3 * 3, grid_ch_dim)).astype(jnp.float32)\n",
    "x = run_circuit(params, wires, inp, training)\n",
    "print('INPUT SHAPE', inp.shape)\n",
    "print('OUTPUT SHAPE', x.shape)\n",
    "\n",
    "\n",
    "# --- ADICIÓN CLAVE PARA EVITAR VALUERROR (Simulación de Grafo) ---\n",
    "\n",
    "batch_size = 1\n",
    "N = 5 # Tamaño de la grilla de prueba\n",
    "MAX_NEIGHBORS = 9\n",
    "N_total_test = N * N # 25 nodos\n",
    "\n",
    "# ADICIÓN 1: Crear un tensor de adyacencia de prueba\n",
    "# JAX espera un tensor con shape (N_nodos, 9). Usamos un placeholder simple\n",
    "# que simula 9 inputs por cada uno de los 25 nodos, indexados de 0 a 24.\n",
    "adjacency_indices_padded_test = jnp.arange(N_total_test * MAX_NEIGHBORS).reshape(N_total_test, MAX_NEIGHBORS) % N_total_test\n",
    "\n",
    "\n",
    "# Run for 10 iterations\n",
    "num_steps = 10\n",
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "# ADICIÓN 2: Pasar el noveno argumento (el tensor de adyacencia)\n",
    "x = v_run_iter_nca(\n",
    "    grid, \n",
    "    params, \n",
    "    wires, \n",
    "    True, \n",
    "    True, \n",
    "    num_steps, \n",
    "    False, \n",
    "    subkey,\n",
    "    adjacency_indices_padded_test # <--- NOVENO ARGUMENTO AÑADIDO\n",
    ")\n",
    "\n",
    "\n",
    "print('Output shape', x.shape)\n",
    "\n",
    "assert x.shape == (batch_size, N, N, C)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Growing the Lizard: testing generalization\n",
    "\n",
    "Visualization of the recurrent dynamics of the\n",
    "learned circuit on a grid twice the size of the training grid.\n",
    "\n",
    "\n",
    "grid = jnp.zeros(\n",
    "    shape=(\n",
    "        TARGET_SIZE_EMOJI * 2,\n",
    "        TARGET_SIZE_EMOJI * 2,\n",
    "        hyperparams['channels'],\n",
    "    )\n",
    ")\n",
    "\n",
    "# Seed\n",
    "grid = grid.at[TARGET_SIZE_EMOJI * 2 // 2, TARGET_SIZE_EMOJI * 2 // 2, :].set(1)\n",
    "\n",
    "params, opt_state, key = train_state\n",
    "wires = wires\n",
    "training = False\n",
    "periodic = True\n",
    "\n",
    "print(grid.shape)\n",
    "frames = []\n",
    "nca_state = grid\n",
    "frames.append(zoom(nca_state[:, :, 0], 8))\n",
    "for i in range(12):\n",
    "  nca_state = run_sync(nca_state, params, wires, training, periodic, adjacency_indices_padded_lizard)\n",
    "  frames.append(zoom(nca_state[:, :, 0], 8))\n",
    "\n",
    "visualize(frames, 'lizard.gif', 5)\n",
    "Image('lizard.gif') \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# --- Funciones de Pérdida y Entrenamiento (Se redefinen para Lizard, pero se necesitan aquí globalmente si se llama desde otros tests) ---\n",
    "\n",
    "def loss_f_global(params, wires, train_x, train_y, periodic, num_steps, async_training, key, adjacency_indices_padded):\n",
    "  # Esta versión global es solo para asegurar que v_run_iter_nca pueda ser llamada.\n",
    "  # La versión específica del Lizard (Celda 39) sobrescribe esto.\n",
    "  def eval(params, training):\n",
    "    y = v_run_iter_nca(\n",
    "        train_x, params, wires, training, periodic, num_steps, async_training, key, adjacency_indices_padded\n",
    "    )\n",
    "    # Usar una pérdida genérica que no rompa\n",
    "    return jax.numpy.square(y).sum() \n",
    "\n",
    "  return eval(params, 1), {'hard': eval(params, 0)}\n",
    "\n",
    "val_and_grad_global = jax.value_and_grad(loss_f_global, argnums=0, has_aux=True)\n",
    "\n",
    "# Helper function\n",
    "upd_f = lambda p: p\n",
    "\n",
    "# Nota: La definición de train_step para el Lizard se encuentra en la Celda 39 y usa la variable correcta.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Growing the Lizard: testing generalization\n",
    "\n",
    "Visualization of the recurrent dynamics of the\n",
    "learned circuit on a grid twice the size of the training grid.\n",
    "\n",
    "\n",
    "grid = jnp.zeros(\n",
    "    shape=(\n",
    "        TARGET_SIZE_EMOJI * 2,\n",
    "        TARGET_SIZE_EMOJI * 2,\n",
    "        hyperparams['channels'],\n",
    "    )\n",
    ")\n",
    "\n",
    "# Seed\n",
    "grid = grid.at[TARGET_SIZE_EMOJI * 2 // 2, TARGET_SIZE_EMOJI * 2 // 2, :].set(1)\n",
    "\n",
    "params, opt_state, key = train_state\n",
    "wires = wires\n",
    "training = False\n",
    "periodic = True\n",
    "\n",
    "print(grid.shape)\n",
    "frames = []\n",
    "nca_state = grid\n",
    "frames.append(zoom(nca_state[:, :, 0], 8))\n",
    "for i in range(12):\n",
    "  nca_state = run_sync(nca_state, params, wires, training, periodic, adjacency_indices_padded_lizard)\n",
    "  frames.append(zoom(nca_state[:, :, 0], 8))\n",
    "\n",
    "visualize(frames, 'lizard.gif', 5)\n",
    "Image('lizard.gif')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Test de Verificación de Dimensiones (Modificada)\n",
    "key = jax.random.PRNGKey(0)\n",
    "key_init, key = jax.random.split(key, 2)\n",
    "n_kernels = 4\n",
    "layers = [128] * 10 + [64, 32, 16]\n",
    "connections = ['unique'] * len(layers)\n",
    "\n",
    "\n",
    "hyperparams = {\n",
    "    'update': {'layers': layers, 'connections': connections},\n",
    "    'perceive': {\n",
    "        'n_kernels': n_kernels,\n",
    "        'layers': [9, 8, 4, 2, 1],\n",
    "        # CORRECCIÓN 1: Usar 'unique' en lugar de 'first_kernel'\n",
    "        'connections': ['unique', 'unique', 'unique', 'unique'], \n",
    "    },\n",
    "}\n",
    "\n",
    "training = True\n",
    "params, wires = init_diff_logic_ca(hyperparams, key_init)\n",
    "print(\n",
    "    params['perceive'][0]\n",
    "    .reshape((\n",
    "        hyperparams['perceive']['n_kernels'],\n",
    "        hyperparams['perceive']['layers'][1],\n",
    "        16,\n",
    "    ))\n",
    "    .shape\n",
    ")\n",
    "grid_ch_dim = 16\n",
    "inp = jnp.ones((3 * 3, grid_ch_dim)).astype(jnp.float32)\n",
    "x = run_circuit(params, wires, inp, training)\n",
    "print('INPUT SHAPE', inp.shape)\n",
    "print('OUTPUT SHAPE', x.shape)\n",
    "\n",
    "\n",
    "# --- ADICIÓN CLAVE PARA EVITAR VALUERROR (Simulación de Grafo) ---\n",
    "\n",
    "batch_size = 1\n",
    "N = 5 # Tamaño de la grilla de prueba\n",
    "MAX_NEIGHBORS = 9\n",
    "N_total_test = N * N # 25 nodos\n",
    "\n",
    "# ADICIÓN 1: Crear un tensor de adyacencia de prueba\n",
    "# JAX espera un tensor con shape (N_nodos, 9). Usamos un placeholder simple\n",
    "# que simula 9 inputs por cada uno de los 25 nodos, indexados de 0 a 24.\n",
    "adjacency_indices_padded_test = jnp.arange(N_total_test * MAX_NEIGHBORS).reshape(N_total_test, MAX_NEIGHBORS) % N_total_test\n",
    "\n",
    "# --- Definición de GRID (AÑADIR ESTO) ---\n",
    "N = 5\n",
    "C = 8\n",
    "batch_size = 1 # O el batch_size que desees\n",
    "grid = random.randint(key, (batch_size, N, N, C), minval=0, maxval=2).astype(jnp.float32)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Run for 10 iterations\n",
    "num_steps = 10\n",
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "# ADICIÓN 2: Pasar el noveno argumento (el tensor de adyacencia)\n",
    "x = v_run_iter_nca(\n",
    "    grid, \n",
    "    params, \n",
    "    wires, \n",
    "    True, \n",
    "    True, \n",
    "    num_steps, \n",
    "    False, \n",
    "    subkey,\n",
    "    adjacency_indices_padded_test # <--- NOVENO ARGUMENTO AÑADIDO\n",
    ")\n",
    "\n",
    "\n",
    "print('Output shape', x.shape)\n",
    "\n",
    "assert x.shape == (batch_size, N, N, C)\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
